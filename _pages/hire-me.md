---
layout: single
title: Hire me
date: 2024-06-04
type: page
published: false
status: publish
permalink: /hire-me/
categories: []
tags: []
---


I'm looking for my next role, and if you don't already know me, my background
doesn't fit in an exact box, so I am writing a long form version of the type of
company I want to work for and the type of role I would like to have.

Send me an email

Book a video call with me

Download my Resume

## About me

* Empathetic leader: I like to see others succeed.

## My Skills

### Customer Success, Product Education, Education 

* **Customer Success** 


### Company culture & People Management

* **Hiring, Performance Evaluation, Management:** As a leader of the
  Infrastructure Team at The Carpentries, I had the opportunity to hire
  wonderful colleagues. I led or contributed to the hiring process of 5+
  positions (full time and contractors). I directly supervised, including
  leading their annual performance evalution, 6 people (UX/UI Designers,
  Python/Django Developers, Software Engineers) working on different technical
  projects.
* **Diversity, Equity, and Inclusion:** Creating a work environment where
  diversity is embraced, celebrated, and nurtured, is a thoughtful process that
  needs to be continuously evaluated and adjusted. I have contributed in
  developing work policies that champion equity and inclusion. For instance, by
  anticipating accommodations during the hiring process or by respecting
  preferred communication methods with co-workers, it creates a safer space
  where everyone can do their best work.
* **Remote Team Management:** Having colleagues across time zones with different
  constraints on their schedules, and that you only get to see in person once a
  year require implementing strategies to ensure effective communication and
  team work. Running meetings with intention, developing communication norms,
  working in the open, having processes in place for decision making are some
  examples of things I have experience implementing and that make remote work
  enjoyable and effective.


### Product and Project Management

* **GDPR compliance**. I liaised with a team of lawyers to identify changes
  needed in The Carpentries data management practices to be compliant with GDPR.
  I developed a roadmap, supervised the implementation or directly implemented
  changes needed in the infrastructure, and documented processes and policies.
* **Data management system** ([AMY](https://github.com/carpentries/amy)) 
  is an open source Django application that manages data about people, events,
  members, and lessons for The Carpentries. For about 2 years, I worked with
  contractors to roadmap features, develop their specifications, review and test
  code changes. Most of these features were related to implementing data
  management practices for GDPR compliance.
* **Lesson Infrastructure** Since the beginning of volunteering with The
  Carpentries in 2014, I started to contribute to the lesson template. These
  contributions gave me a chance to understand what was difficult for newcomers
  to contribute content to the lessons or to use the template for their own
  lessons. I started to develop a vision and a roadmap to implement a new system
  based on RMarkdown and GitHub Actions to lower the technical barriers to
  contribute to Carpentries lessons. I wrote grant proposals that were funded by
  the [R
  consortium](https://www.r-consortium.org/all-projects/awarded-projects/2018-group-1#developing+tools+and+templates+for+teaching+materials)
  (2018) and [CZI](https://carpentries.org/blog/2019/11/czi-moore-grant/)
  (2019). I managed [Zhian Kamvar](https://zkamvar.netlify.app/about/) who
  developed my initial vision into an amazing, fully functional, product: [The
  Carpentries Workbench](https://carpentries.github.io/workbench/).
* **Grants and Academic Publications** Both during my time in academia and at
  The Carpentries, I managed the budget, the deliverables, and reporting
  associated with grant funding. During my time in academia, I authored and
  co-authored [20+ scientific
  publications](https://scholar.google.com/citations?view_op=list_works&hl=en&hl=en&user=6wJ8BtAAAAAJ),
  including the description of [a new species of sea cucumber]({% post_url
  2014-01-31-phyrella-revision %}) which was featured on [Boing
  Boing](https://boingboing.net/2014/02/11/sea-cucumber-named-for-dog.html).

### Programming and Data Analysis

* **R**: I am the most familiar with the R programming language. I started using
  it 2004, and never stopped.
  - For data analysis and visualization, I have extensive experience with all
    the packages of the `{tidyverse}` (`{dplyr}`, `{ggplot2}`, `{purrr}`,
    `{tidyr}`, etc.). I have the Tidyverse Trainer certification from RStudio
    (now Posit) and was an Examiner for this certification. On the statistical
    side, I have experience with linear models (including GLMs) and Bayesian statistics.
  - On the programming side, I am maintaining 6 packages on CRAN. I enjoy
    developing solutions that interact with Web APIs or scrape web pages. For
    instance, my most popular packages are:
    + [`{foghorn}`](https://fmichonneau.github.io/foghorn/) which brings CRAN
      check results directly to your terminal (58K downloads/month).
    + [`{rotl}`](https://docs.ropensci.org/rotl/) which uses the OpenTree of
      Life web API to R (used in 370+ peer-reviewed publications).
    + [`naturalist_bot`](https://botsin.space/naturalist_bot) is a Mastodon bot
      that posts iNaturalist observations every 6 hours.
  - I have extensive experience putting R scripts and Shiny applications in
    production using Docker, and deploying them on AWS.
* **Git, GitHub, GitHub Actions:** I use Git and GitHub to version control my
  code (and many other documents). I use GitHub Actions for continuous
  integration, running cron jobs, checking website links, and posting for my
  Mastodon bot.
* **Databases:** I have used PostgreSQL (with the PostGIS extension) to manage
  data for research projects and in enterprise settings. More recently, I have
  started to use DuckDB to analyze large and complex datasets. At Voltron Data,
  I had the opportunity to learn and use Apache Arrow, including the Python and
  the R bindings.


### DevOps and DataOps

* **Linux/Ubuntu**: I have been using Ubuntu as my daily operating system since
  2006, and on any cloud instance I have ever created. My sysadmin knowledge is
  all self-taught but I know enough to know where to look when something goes
  wrong to diagnose an issue and find a solution.
* **Cloud Providers (AWS, Digital Ocean)**: I have most experience with AWS and
  Digital Ocean but I have also used Google Cloud. With AWS, I set up the
  technical infrastructure of The Carpentries to run on EC2 and S3 (static site
  hosting and backups), used Route53 to manage domains, and RDS to manage
  databases.
* **Docker**: I developed several web apps coded in R and Shiny that I bundled
  with Docker Compose to make it easy to maintain and deploy. These applications
  typically also used Let's Encrypt to manage the SSL certificates, and Redis to
  cache remote data.
* **Data Pipelines**: For one of my most complex research projects, I developed
  a data processing pipeline that fetches millions of records from multiple
  biodiversity public repositories, reconciliate them and their associated
  species names, before analyzing them. I wrote this type of pipeline in R using
  the `{remake}` package and PostgreSQL. I have started to revisit this project
  to use tools that are better suited but didn't exist when I started this
  project: `{targets}` and DuckDB.
* **Database connectors**: During my tenure at Voltron Data, I had the
  opportunity to learn about and use in benchmarking tests the different
  database connectivity protocols such as ODBC, JDBC, and ADBC.









## About me

* Growth mindset
* Continuous learning




As far as back as I can remember I wanted to be a marine biologist. In 2006, I
had the opportunity to do a PhD at the university of Florida that made this
dream come true. Over the following 8 years, I organized field expeditions
across many places (some more remote than others) to look for sea cucumbers.

When I was not travelling, I was organizing and analyzing the data I collected
during these field expeditions. I had started to use Linux and program in R
during my Master, so it is what I used to do it. I cared about reproducibility
(I still do), so I was using R and Bash to automate my data analysis pipelines.
When new data would come in, I was able to get them integrated into my existing
results. I would use this to detect if I had collected a new species of sea
cucumbers for instance. In the meantime, I started to get involved in the
development of a couple of open source R packages for dealing with phylogenetic
data, and contributed to, before becoming the maintainer of, `phylobase`.

Towards the end of my PhD, I saw many of colleagues graduate student struggle
with their data analyses. Many of them dealt with lots of genomics data but only
had Excel skills to work with it. Because I wanted to share my programming
knowledge, I approach the chair of the department who agreed to let me teach an
R programming class for biologists. As I was developing the content for this
course, I wanted to understand what others were doing. That's how I came across
Software Carpentry. At the time, the organization was teaching 2-day workshops
to researchers who wanted to learn best practices in scientific computing,
including an introduction to R. I started the process to become a certified
Instructor so I could teach these workshops. A few months later, a new spin-off
organization was founded: Data Carpentry. I used the last bit of grant money I
had available to attend their inaugural workshops. I met the team who had
already planned to do their next workshop at the University of Florida. When
they asked if I'd be interested in teaching the R section at that workshop, I
gladly accepted.

[ add paragraph about biodiversity data postdoc ]

I contributed major changes to the lesson before and after the workshop at UF.
As Data Carpentry was new there was lots of demand to teach the curriculum.
Teaching these workshops showed me that I really enjoyed sharing my programming
knowledge and gave me an appreciation for the impact that these 2 short days had
on the participants, their research, and their careers.

In the meantime, my academic research turned into developing a reproducible and
automated data pipeline to understand how much information was available in
public database about marine biodiversity of the continental USA. I
reconcialiated millions of database records fetched from web APIs, scrapped from
websites and the litterature. I combined all this information into a PostgreSQL
database with the PostGIS extension to be able to do some geospatial queries.



So, when a position was available to join the organization as an employee, I did
not hesitate.

As I joined, Software Carpentry and Data Carpentry merged under a single
umbrella, The Carpentries. I started by leading the curriculum development
efforts. It meant that I managed the community of lesson maintainers,
contributed to adding new features to the lesson template, and wrote new
lessons. I was also in charge of managing the lesson release process, which
meant reconciliating data from multiple sources to acknowledge all the people
who had contributed to improving the lessons. I also acted as a liaison with
researchers who were interested in collaborating with us to develop new lessons
and coming up with funding mechanisms to support the development of these
lessons.

About 6 months into my tenure at The Carpentries, I became in charge of all the
technological infrastructure. I migrated and centralized all our services to run
on AWS (using EC2, S3, Route53, Cloudfront, RDS). I also used a combination of R
(including Shiny and RMarkdown), Docker, and some Bash, to develope an alert
system to detect infrastructure issues early, put in place automated pipelines
to make data publicly available, and automated report generation.

On March 16th, 2022, I became Senior Director of Technology which meant that I
became part of the Executive Team at The Carpentries. The next day COVID
lockdown were in effect, and the way The Carpentries operated had to be
reinvented as our in-person workshops had now have to be taught online. For the
following 2.5 years, I contributed to the daily management of the operations for
the organization. Leading the infrastructure team meant that I was in charge of
three main projects:

- I led the hiring and managed the team in charge of re-implementing from
  scratch the lesson template for the Carpentries (software developer and
  UX/UI designers)
- I managed the

I worked on the technical side with The covid,
online workshops. Managing team. Hiring contractors, GDPR. Product management.
Writing grants


Arrow, DuckDB (including geospatial), Database connectivity protocols





I will strongly consider the following:

1. Customer Success

2. Developer Advocate

3. Data Science/ML/MLOps/Data Engineer 


Working on smaller teams where I can do many different things. I like to be able to work on multiple projects at once. 

Nice to have:
* Domains: 





## Remote Work

* I'm looking for a remote position. I live in France.
* For many, remote work started with the COVID-19 pandemic, but I have been
  working in some kind of remote capacity since 2015. I have experienced
  different ways of doing remote work and I prefer working for organizations
  that have put a lot of thoughts into what it means to have a distributed
  workforce. Specifically, organizations that have processes in place to be able
  to share progress and come to a concensus asynchronously. For instance, that
  means that meetings are used to take full advantage of having everyone
  together (weekly updates can be shared with the rest of the team in writing).
  It also means that there are processes in place to keep notes that can be used
  to understand how a decision has been made so if people are missing the
  meeting they can go back to the notes and know what happened.


## What others have said about working with me